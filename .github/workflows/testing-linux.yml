name: Minimal and full tests on Linux
on: pull_request
jobs:
  run:
    name: Minimal and full tests on Linux with Python ${{ matrix.python-version }}
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
          python-version: [3.7, 3.8]
    steps:
      - uses: s-weigand/setup-conda@v1
      - uses: actions/checkout@v2
      - run: git fetch --prune --unshallow --tags
      - name: Setup Python ${{ matrix.python-version }}
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python-version }}
      - name: Install pytest
        run: |
          pip install pytest
          pip install pytest-cov

      - name: Install nwb-conversion-tools with minimal requirements
        run: |
          pip install -e .
          pip install --no-deps git+https://github.com/catalystneuro/hdmf.git@generic_data_chunk
      - name: Run minimal pytest with coverage
        run: pytest tests/test_internals --cov=./ --cov-report xml:/home/runner/work/nwb-conversion-tools/nwb-conversion-tools/minimal-coverage.xml
      - name: Upload minimal coverage to Codecov
        uses: codecov/codecov-action@v1
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          file: /home/runner/work/nwb-conversion-tools/nwb-conversion-tools/minimal-coverage.xml
          flags: unittests
          name: codecov-umbrella 
          yml: /home/runner/work/nwb-conversion-tools/nwb-conversion-tools/codecov.yml

      - name: Install full requirements
        run: |
          pip install -r requirements-full.txt
          pip install --no-deps git+https://github.com/catalystneuro/hdmf.git@generic_data_chunk
      - name: Get ephy_testing_data current head hash
        id: ephys
        run: echo "::set-output name=HASH_EPHY_DATASET::$(git ls-remote https://gin.g-node.org/NeuralEnsemble/ephy_testing_data.git HEAD | cut -f1)"
      - name: Cache ephys dataset - ${{ steps.ephys.outputs.HASH_EPHYS_DATASET }}
        uses: actions/cache@v2
        id: cache-datasets
        with:
          path: /home/runner/work/nwb-conversion-tools/nwb-conversion-tools/ephy_testing_data
          key: ecephys-datasets-8-${{ steps.ephys.outputs.HASH_EPHY_DATASET }}
          restore-keys: ecephys-datasets-8-${{ steps.ephys.outputs.HASH_EPHY_DATASET }}
      - name: Force GIN download
        if: steps.cache-datasets.outputs.cache-hit == false
        run: |
          conda install -c conda-forge datalad==0.14.5
          git config --global user.email "CI@example.com"
          git config --global user.name "CI Almighty"
          datalad install https://gin.g-node.org/NeuralEnsemble/ephy_testing_data
          cd ephy_testing_data
          datalad get -r ./neuralynx/Cheetah_v5.7.4/original_data/
          datalad get -r ./neuroscope/test1/
          datalad get -r ./openephysbinary/v0.4.4.1_with_video_tracking/
          datalad get -r ./blackrock/
          datalad get -r ./intan/
          datalad get -r ./spikegadgets/
          datalad get -r ./spikeglx/Noise4Sam_g0/Noise4Sam_g0_imec0/
          datalad get -r ./phy/phy_example_0/
          datalad get -r ./blackrock/
          datalad get -r ./axona/
      - name: Run full pytest with coverage
        run: pytest --cov=./ --cov-report xml:/home/runner/work/nwb-conversion-tools/nwb-conversion-tools/coverage.xml
      - name: Upload full coverage to Codecov
        uses: codecov/codecov-action@v1
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          file: /home/runner/work/nwb-conversion-tools/nwb-conversion-tools/coverage.xml
          flags: unittests
          name: codecov-umbrella 
          yml: /home/runner/work/nwb-conversion-tools/nwb-conversion-tools/codecov.yml
